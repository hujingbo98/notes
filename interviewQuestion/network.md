<!--
 * @Author : Hu Jingbo
 * @Date   : 2021-11-19
-->

[toc]

# 网络

## 网络协议

### 什么是 OSI 七层协议？

OSI 七层协议包括：物理层，数据链路层，网络层，传输层，会话层，表示层，应用层。

物理层主要解决两台物理机之间的通信，通过二进制比特流的传输来实现，二进制数据表现为电流电压上的强弱，到达目的地再转化为二进制机器码。网卡、集线器工作在这一层。

数据链路层在不可靠的物理介质上提供可靠的传输，接收来自物理层的比特流形式的数据，并封装成帧，传送到上一层；同样，也将来自上层的数据帧，拆装为比特流形式的数据转发到物理层。这一层在物理层提供的比特流的基础上，通过差错控制、流量控制方法，使有差错的物理线路变为无差错的数据链路。提供物理地址寻址功能。交换机工作在这一层。

网络层将网络地址翻译成对应的物理地址，并决定如何将数据从发送方路由到接收方，通过路由选择算法为分组通过通信子网选择最佳路径。路由器工作在这一层。

传输层提供了进程间的逻辑通信，传输层向高层用户屏蔽了下面网络层的核心细节，使应用程序看起来像是在两个传输层实体之间有一条端到端的逻辑通信信道。

会话层建立会话：身份验证，权限鉴定等； 保持会话：对该会话进行维护，在会话维持期间两者可以随时使用这条会话传输局； 断开会话：当应用程序或应用层规定的超时时间到期后，OSI会话层才会释放这条会话。

表示层对数据格式进行编译，对收到或发出的数据根据应用层的特征进行处理，如处理为文字、图片、音频、视频、文档等，还可以对压缩文件进行解压缩、对加密文件进行解密等。

应用层提供应用层协议，如HTTP协议，FTP协议等等，方便应用程序之间进行通信。

### 什么是 TCP/IP 四层协议？

TCP/IP 协议族包括四层，分别是链路层、网络层、传输层、应用层。

链路层对应 OSI 的物理层和数据链路层，通常包括操作系统中的设备驱动程序和计算机中对应的网络接口卡。

网络层协议包括 IP 协议（网际协议），ICMP 协议（Internet 互联网控制报文协议），以及 IGMP 协议（Internet 组管理协议）。

传输层协议包括 TCP 协议（传输控制协议），UDP 协议（用户数据报协议）。

应用层协议包括 Telenet 远程登录，FTP 文件传输协议，HTTP 超文本协议，SMTP 简单邮件传输协议，SNMP 简单网络管理协议。

### 什么是字节序？

字节序(Byte order)是指多字节数据在内存中或在网络传输中时的存储顺序，低地址存低位为小端(Little endian)，高地址存低位为大端(Big endian)。

可以使用 linux 命令 lscpu 来查看字节序。也可以自定义程序来判断字节序：定义一个联合体，联合体中有 short 类型和 char 类型，令 short 等于 1，如果 char 数据等于 1 则是小端，否则是大端。

```c++
bool is_little_endian()
{
    union tt
    {
        short a;
        char b;
    } c;
    c.a = 1;
    return 1 == c.b ? true : false;
}
```

## TCP

### 什么是 TCP？什么时候用？

TCP (Transmission Control Protocol) 为应用层提供一种面向连接、可靠的字节流服务。

面向连接是指三次握手和四次挥手；可靠是指数据校验、消息确认、超时重传、流量控制、拥塞控制等机制；字节流是指 TCP 将待发送的数据保存在内核发送缓冲区中，将数据分段发出，将接收的数据排序后保存在内核接收缓冲区中，接收缓冲区的数据应用层想取多少就取多少，不必每次取出一整个报文段。

在对数据的完整性和确定性要求较高的情况下需要使用 TCP，如文件传输、邮件等。

### TCP 如何实现可靠性？

TCP 通过下列方式来提供可靠性。三次握手，四次挥手，数据分段、排序、校验(差错丢弃不确认)，消息确认(延时确认，200ms)，超时重传，丢弃重复报文段，流量控制(窗口大小)。

### 什么是 TCP 三次握手？

建立一个 TCP 连接需要三次握手。

第 1 次握手，请求端发送一个 SYN 段指明客户打算连接的服务器的端口，以及初始序号 (ISN)。请求端进入 SYN-SEND 状态，等待服务端确认。

第 2 次握手，服务器发回包含服务器的初始序号的 SYN 报文段作为应答。同时，将确认序号设置为客户的 ISN 加 1 以对客户的 SYN 报文段进行确认，一个 SYN 将占用一个序号。服务端进入 SYN-RECD 状态，等待客户端确认。

第 3 次握手，请求端将确认序号设置为服务器的 ISN 加 1 以对服务器的 SYN 报文段进行确认。

### 建立连接两次握手行不行？

TCP 建立连接需要告知对方自己的初始序号，并确认对方已经收到。如果建立连接小于三次握手，至多只有请求端的初始序号被确认，服务器的初始序号得不到确认。因此建立一个 TCP 连接需要三次握手。

另外三次握手可以防止已失效的连接请求连接报文段又传输到了服务器。比如，客户端发送一个连接请求 SYN 段到服务器，由于网络阻塞等原因，服务器没收到此 SYN；于是客户端重传 SYN，连接成功并数据传输完毕后，关闭了 TCP 连接；在关闭连接后，如果客户端发出的第一个 SYN 在某个时间才到达服务器，此时服务器误认为客户端又发出一次连接请求，于是向客户端发出自己的 SYN + ACK 段；如果不采用三次握手，此时服务器就已经建立新的连接了，然而客户端并不会响应服务器的 ACK，且不会发送数据，则服务器一直等待，浪费资源。

### ISN 是什么？

ISN 随时间的变化，因此每个连接都将拥有不同的 ISN，RFC 793 指出 ISN 可以看作是一个 32 比特的计数器，每 4ms 加 1。

在 4.4BSD (和多数伯克利的实现版) 中，系统初始化时初始序号被初始化为 1。这种方法违背了 Host Requirements RFC (在这个代码中的一个注释确认这是一个错误)。这个变量每 0.5秒 增加 64000，并每隔 9.5 小时又回到 0 (对应这个计数器每 8ms 加 1，而不是 4ms 加 1)。另外，每建立一次连接后，这个变量将增加 64000。

### TCP 是如何处理建立连接超时的？

很多情况导致无法建立连接，一种情况是服务器主机没有处于正常状态。这时，客户端会重传 SYN 报文段，第 2 个 SYN 与 第 1 个的时间间隔为 5.5 ~ 6 秒，第 3 个与第 2 个的间隔是 24 秒。大多数 Berkeley 系统将建立一个新连接的最长时间限制在 75 秒以内，也就是说，请求端将在第 3 个 SYN 报文段发出后大约 45 秒放弃连接。

为什么第一次超时时间为 5.5 ~ 6 秒，这是因为 BSD 版的 TCP 软件采用一种 500 ms 的定时器，建立一个 6 秒的定时器 (12 个时钟滴答(tick))，滴答计数器可能在 0 ~ 500 ms (第一个时钟滴答) 中的任意时刻减 1。 当滴答计数器为 0 时，6秒的定时器便会超时，这个定时器会在 24 秒 (48 个时钟滴答) 重新复位，所以第二次的超时时间将会更接近 24 秒。

### 什么是 MSS？

最大报文长度 (MSS, Maximum Segment Size) 表示 TCP 传往另一端的的最大数据块的长度。在建立一个 TCP 连接时，每一方通常都在第一个报文段 (SYN 报文段) 中指明这个选项。

### TCP 的半连接？

三次握手中，主动发起握手的一方不发最后一次 ACK，使得服务器端阻塞在 SYN_RECD 状态。当服务器处于 SYN_RCVD 状态，服务器会把此种状态下请求连接放在一个队列里，该队列称为半连接队列。

SYN 洪水攻击 (SYN Flood Attack) 就是利用了 TCP 的半连接状态。

### 什么是 SYN 洪水攻击？原理？怎么避免？

SYN 洪水攻击 (SYN Flood Attack) 是当前最流行的拒绝服务攻击 (DOS, Denial Of Service) 和分布式拒绝服务攻击 (DDOS, Distributed Denial Of Service)，这是一种利用 TCP 协议缺陷，发送大量伪造的 TCP 连接请求，使被攻击方资源耗尽 (CPU 满负荷或内存不足) 的攻击方式。

**具体原理是：**

在 TCP 连接的三次握手中，请求端不发最后一次 ACK，使得服务器端阻塞在半连接状态 (SYN_RECD)，这将占用服务器的 CPU 和 内存资源。

在收到请求端的 SYN 段时，服务器会先分配 TCB (Transmission Contrl Block)，通常一个 TCB 至少需要 280 字节，有些操作系统甚至需要 1300 字节。并且 TCP 服务器会进行超时重传 SYN + ACK 段，然后等待一段时间后丢弃这个未完成的连接，一般来说这个时间是分钟级的 (大约为 30 秒到 2 分钟)。

如果恶意攻击者大量模拟这种情况，那么服务端将会维护一个非常大的半连接队列而消耗非常多的内存资源，还要不断对这个队列进行 SYN + ACK 的重传，这将消耗非常多的 CPU 资源。

如果服务器的 TCP/IP 栈不够健壮，那么最后的结果是堆栈溢出崩溃。即使服务器的系统足够健壮，服务器也将忙于处理攻击者伪造的 TCP 连接请求而顾不上客户的正常请求。此时，从正常客户的角度看来，服务器失去响应。

**防止 SYN 攻击的方案有:**

* 缩短 SYN 确认超时时间

* 记录 IP，若连续受到某个 IP 的重复 SYN 报文，从这个 IP 地址来的包会被一概丢弃。

* 无效连接的监视释放  

监视系统的半连接和不活动连接，当达到一定阈值时释放这些连接，从而释放系统资源。这种方法对于所有的连接一视同仁，而且由于 SYN Flood 造成的半连接数量很大，正常连接请求也被淹没在其中被这种方式误释放掉，因此这种方法属于入门级的防止 SYN Flood 方法。

* 延缓 TCB 分配方法  

消耗服务器内存资源主要是因为当 SYN 数据报文一到达，系统立即分配 TCB，从而占用了资源。而 SYN Flood 由于很难建立起正常连接，因此，当正常连接建立起来后再分配 TCB 则可以有效地减轻服务器资源的消耗。常见的方法是使用 SYN Cache 和 SYN Cookie 技术。

SYN Cache 技术是在系统收到一个 SYN 报文时，用一个 hash 表保存这种半连接信息（包括序列号），直到收到正确的 ACK 报文再分配 TCB，这个开销远小于 TCB 的开销。  

SYN Cookie 技术则完全不使用任何存储资源，这种方法比较巧妙，它使用一种特殊的算法生成 Sequence Number，这种算法考虑到了对方的IP、Port、己方IP、Port 的固定信息，以及对方无法知道而己方比较固定的一些信息，如 MSS、MSL 等，在收到对方的 ACK 报文后，重新计算一遍，看其是否与对方回应报文中的 (Sequence Number - 1) 相同，从而决定是否分配 TCB 资源。

* 使用 SYN Proxy 防火墙  

一种方式是防火墙确认连接的有效性后，防火墙才会向内部服务器发起 SYN 请求。防火墙代服务器发出的 SYN ACK 包使用的序列号为 s, 而真正的服务器回应的序列号为 s', 这样，在每个数据报文经过防火墙的时候进行序列号的修改。

另一种方式是防火墙确定了连接的安全后，会发出一个 safe reset 命令，client 会进行重新连接，这时出现的 SYN 报文会直接放行。这样不需要修改序列号了。但是，client 需要发起两次握手过程，因此建立连接的时间将会延长。

### 什么是 TCP 四次挥手？三次行不行？

TCP 终止连接过程中首先进行关闭的一方称为将执行主动关闭，而另一方执行被动关闭。

1) 第 1 次挥手，主动关闭方发送一个 FIN，用来关闭主动关闭方到被动关闭方的数据传输，主动关闭方进入 FIN_WAIT_1 状态，等待被动关闭方的确认。

2) 第 2 次挥手，当被动关闭方收到这个 FIN，它发回一个 ACK，确认序号为收到的序号加 1。被动关闭方进入 CLOSE_WAIT 状态。和 SYN 一样，一个 FIN 将占用一个序号。主动关闭方收到 ACK 进入 FIN_WAIT_2 状态。TCP 协议栈为 FIN 包插入到文件结束符 EOF 缓冲区，应用程序通过调用 read 函数感应 FIN 包。

3) 第 3 次挥手，被动关闭方读到 EOF，应用程序调用 close 函数关闭它的套接字，导致被动关闭方发送一个 FIN，被动关闭方进入 LAST_ACK 状态。

4) 第 4 次挥手，主动关闭方收到 FIN，发回一个 ACK，确认序号为收到序号加 1。主动关闭方进入 TIME_WAIT 状态。

TCP 终止连接需要四次挥手，这是因为当被动关闭方收到主动关闭方的 FIN 数据包后，被动关闭方可能还有数据没有发完，不能立即 close。所以被动关闭方先发送 ACK 确认主动关闭方的 FIN。然后发送剩下的数据，发完之后再发送 FIN 包给主动关闭方，表示发送完毕。然后主动关闭方发送 ACK 终止连接。

### 什么是 2 MSL？为什么要有 2 MSL 状态？2 MSL 状态可以关闭吗？

TIME_WAIT 状态也称 2MSL 等待状态。每个具体的 TCP 实现必须选择一个报文段的最大生存时间 MSL(Maximum Segment Lifetime)。它是任何报文段在被丢弃前在网络内的最长时间。这个时间是有限的，因为 TCP 报文段以 IP 数据报在网络中传输，而 IP 数据报则是有限制其生存时间的 TTL 字段。

RFC 793 [Postel 1981c] 指出 MSL 为 2 分钟。然而，实现中的常用值是 30 秒，1 分钟，或 2 分钟。

对一个具体实现所给定的 MSL 值，处理的原则是：

1. 当 TCP 执行一个主动关闭，并发回最后一个 ACK，该连接必须在 TIME_WATI 状态停留的时间为 2 倍的 MSL。这样可让 TCP 再次发送最后的 ACK 以防止这个 ACK 丢失(另一端超时并重发最后的 FIN)。

例如，如果主动关闭方发送最后的 ACK 在网络中丢失，这样被动关闭方收不到最后的 ACK。待重传定时器超时，被动关闭方将重传 FIN 到主动关闭方。如果没有 TIME_WAIT 状态，此时主动关闭方应该是 CLOSED 状态。收到重传的 FIN 后，它没有关于此 FIN 的任何信息，所以向被动关闭方发送一个 RST 报文段，被动关闭方收到 RST 后，认为连接出现了异常，而非正常关闭。如果有 TIME_WAIT 状态，收到重传的 FIN 后，将回复一个 ACK 来确认被动关闭方发送 FIN。再进入 TIME_WAIT 状态，2MSL 过后，TCP 连接正常关闭。

是否只要主动关闭方在 TIME_WAIT 状态下停留 2MSL，4次握手就一定能正常完成呢？

不一定，如果被动关闭方重传的 FIN 报文段也在网络中丢失了，主动关闭方在 TIME_WAIT 状态等待 2MSL 没收到任何报文段，进入 CLOSED 状态，被动关闭方就不会收到最后的 ACK。四次握手就没有正常完成。

因此，在 TIME_WAIT 状态等待 2MSL，只是尽量保证正常的 TCP 连接终止序列。

2. 确保老的报文段在网络中消失，不会影响新建立的连接。

例如，主动关闭方发送的最后一个 ACK 由于网络延迟没有按时到达，但并没有超过 MLS 时间，导致被动关闭方重传了一个 FIN，在重传 FIN 后，延迟的 ACK 到达，被动关闭方进入 CLOSED 状态。如果没有 TIME_WAIT 状态，则上述连接已经不存在。现在考虑下面情况，由于上述的连接已经关闭，现在可以马上建立一个与上述 IP 和 Port 等信息相同的新连接。那么当上一个连接重传的 FIN 到达时，被新的连接所接受，这将导致连接被复位。

这种 2MSL 等待的另一个结果是这个 TCP 连接在 2MSL 等待期间，定义这个连接的 socket 不能再被使用。这个连接只能在 2MSL 结束后才能被使用。

某些实现的 API 提供了一种避开这个限制的方法。使用 socket API 时，可说明其中的 SO_REUSEADDR 选项。它将让调用者对处于 2MSL 等待的本地端口进行赋值，但 TCP 原则上避免使用仍处于 2MSL 连接中的端口。

### 什么是 TCP 的半关闭？代码中怎么实现？

TCP 提供了连接的一端在结束了它的发送后还能接收来自另一端数据的能力，这就是所谓的半关闭。

如果应用不调用 close 而调用 shutdown，且第二个参数为 SHUT_WR(1)，则 socket API 支持半关闭。

**半关闭的流程：**

1. 主动关闭方发送一个 FIN。

2. 被动关闭方收到 FIN 回应一个 ACK，并向应用进程交付 EOF。被动关闭方的应用进程调用 read 收到 EOF，此时被动关闭方还可以调用 write 向主动关闭方传输数据。

3. 被动关闭方数据传输完成后，发送一个 FIN。

4. 主动关闭方收到 FIN，发回一个 ACK。主动关闭方进入 TIME_WAIT 状态。

### 什么是平静时间？

如果处于 TIME_WAIT 状态的主机出现故障，假如它在 MSL 内重新启动，并使用故障前仍处于 TIME_WAIT 状态的插口对建立新的连接。那么故障前从这个连接发送的迟到报文段将会被错误的当作新连接的报文段。无论如何选择重启后新连接的初始序号，都会发生这样的情况。

为了防止这种情况，RFC 793 指出 TCP 在启动后的 MSL 秒内不能建立任何连接。这就称为平静时间(Quiet Time)。

### 什么是 FIN_WAIT2 状态？此状态有什么问题吗？

在 FIN_WAIT_2 状态我们已经发出了 FIN，并且另一端也已对它进行确认。除非我们在实行半关闭，否则将等待另一端应用层意识到它已收到一个文件结束符说明，并向我们发送一个 FIN 来关闭另一方向上的连接。只有当另一端完成这个关闭，我们这端才会从 FIN_WAIT_2 进入 TIME_WAIT 状态。

这意味着我们这端可能永远保持这个状态。另一端也将处于 CLOSE_WAIT 状态，并一直保持这个状态直到应用层决定进行关闭。

许多伯克利实现采用如下方式来防止 FIN_WAIT_2 的无限等待。如果执行主动关闭的应用层将进行全关闭，而不是半关闭来说明它还想接收数据，就设置一个定时器。如果这个连接空闲 10 分钟 75 秒，TCP 将进入 CLOSED 状态。在实现代码的注释中确认这个实现代码违背协议的规范。

### 什么是 RST 报文段？

一般来说，无论何时一个报文段发往基准的连接出现错误，TCP 都会发出一个复位报文段。

RST的应用：

* 到不存在的端口的连接请求

* 异常终止一个连接

* 检测半打开连接

### 什么是 TCP 的半打开？

如果一方异常关闭(断网、断电、内核崩溃、机器故障)，而另一方不知情。就处于半打开状态，如果双方不进行通信，是无法发现问题的。可以引入心跳机制，以检测半打开状态，检测到了发送 RST 重新建立连接。

### 什么是糊涂窗口综合征？TCP 是怎么解决的？

糊涂窗口综合症是指当发送端应用进程产生数据很慢或接收端应用进程处理接收缓冲区数据很慢，就会导致 TCP 两端传输的报文段很小，特别是有效载荷很小。极端情况下，有效载荷可能只有 1 个字节，传输开销有 40 字节 (20 字节的 IP 头 + 20 字节的 TCP 头) 。糊涂窗口综合征可发生在 TCP 连接的两端，接收方可以通告一个小的窗口，而发送方也可以发送少量的数据。

接收方的解决方案是不通告小窗口，除非窗口可以增加一个 MSS 大小或者可以增加接收方缓存空间的一半，不论实际有多少。

发送方解决方案是 Nagle 算法，并且只要以下条件之一满足时就发送数据：

1. 可以发送一个满长度的报文段，也就是说待发送的数据长度大于等于一个最大报文段的大小。

2. 可以发送至少是接收方通告窗口大小一半的报文段。

3. 发送端没有还未被确认的数据或者该连接上不使用 Nagle 算法。

### 什么是 Nagle 算法？如何关闭 Nagle 算法？

Nagle 算法要求一个 TCP 连接上最多只能有一个未被确认的小分组，在该分组的确认到达之前不能发送其它的小分组。TCP 将收集这些小分组，并在确认到来时以一个分组的方式发出去。

该算法的优越之处在于它是自适应的，确认到达的越快，数据也就发送的越快。而在希望减少微小分组数目的低速广域网上，则会发送更少的分组。

RFC 声明 TCP 必须实现 Nagle 算法，但必须为应用提供一种方法来关闭该算法在某个连接上执行。关闭 Nagle 算法，socket API 可以使用 TCP_NODELAY 选项来关闭 Nagle 算法。

### 什么是延时确认？为什么要延时？

通常 TCP 在接收到数据时并不立即发送 ACK。相反，它推迟发送，以便将 ACK 与需要沿该方向发送的数据一起发送（有时称这种现象为数据捎带 ACK）。绝大多数实现采用的时延为 200 ms，也就是说，TCP 将以最大 200 ms 的时延等待是否有数据一起发送。

发送 ACK 的实际时间并不都是 200 ms，这是因为 TCP 使用了一个 200 ms 的定时器，该定时器以相对于内核引导的的 200 ms 固定时间溢出。由于需要确认的数据是随机到达的，TCP 在内核的 200 ms 定时器的下一次溢出发出 ACK。这可能是 1 ~ 200 ms 中的任何一刻。

### 什么是流量控制？TCP 有什么机制来实现流量控制？

如果发送方数据发送过快，接收方可能来不及接收，就会造成数据的丢失。所谓流量控制就是让发送方的发送速率不要太快，要让接收方来得及接收。

TCP 的接收方通过通告窗口大小来实现流量控制，发送方使用滑动窗口机制来实现流量控制。

每一个 TCP 报文段都会通告自己的窗口大小，窗口大小是告诉对方自己的接收缓冲区还能放多少字节的数据，TCP 首部中的窗口大小是一个 16 bit 的字段，因此窗口大小最大为 65535 字节。

TCP 的发送方使用滑动窗口机制来实现流量控制，滑动窗口大小不能超过对方的接收窗口大小。滑动窗口的起始位置是内核发送缓冲区中发送并被确认的数据的下一个字节，当数据被发送和确认时，滑动窗口左边沿向右边沿滑动，称为窗口合拢。当另一端的接收进程读取已经确认的数据并释放了 TCP 接收缓冲区时，窗口的右边沿向右滑动将允许发送更多的数据，称为窗口张开。

下图是 TCP 连接中的一方的发送缓冲区使用滑动窗口机制示意图，图中一个数代表一个字节的数据。

```txt
               |-             滑动窗口             -|
               +-----------------------------------+
1     2     3  |  4     5     6  |  7     8     9  |  10     11     12
               +-----------------------------------+
|-发送并被确认 -|-发送但,未被确认 -|-    能够发送    -|- 不能够发送，直至窗口移动 -->
```

### 什么是拥塞控制？ TCP 有什么机制实现拥塞控制？

假设发送方一开始便向网络发送多个报文段，直至达到接收方通告的窗口大小为止。如果在发送方和接收方之间存在多个路由器和速率较慢的链路时，就有可能出现网络拥塞，中间路由器就必须缓存分组，并有可能耗尽存储空间。这种方式严重降低了 TCP 连接的吞吐量。慢启动机制则可以有效地解决此问题。

TCP 通过慢启动算法和拥塞避免算法来实现拥塞控制。

慢启动算法为发送方增加了拥塞窗口 (cwnd, congestion window)。当建立 TCP 连接时，拥塞窗口初始化为 1 个报文段 (即 MSS)。每收到一个 ACK，就增加一个报文段 (cwnd 以字节为单位，但慢启动以报文段大小为单位进行增加)。发送方取拥塞窗口和通告窗口的最小值作为滑动窗口的大小。

慢启动算法在每收到一个 ACK，就增加一个 MSS 大小，看起来是线性增长的，其实它是指数增长的。发送方开始时发送一个报文段，在一个 RTT 时间内收到对方的 ACK，此时拥塞窗口从 1 增加为 2，即可以发送 2 个报文段，在一个 RTT 时间内收到这 2 个报文段的 ACK 时，拥塞窗口就增加为 4。以此类推，下一个就是 8，所以慢启动算法是一种指数增长。

拥塞避免算法要求每次收到一个 ACK 时将 cwnd 增加 1 / MSS，即每经过一个往返时间 RTT 拥塞窗口 cwnd 就增加 1 个 MSS，这是一种线性增长。

拥塞避免是发送方使用的流量控制，而通告窗口则是接收方进行的流量控制。前者是发送方感受到的网络拥塞的估计，而后者则与接收方在该连接上的可用缓存大小有关。

拥塞避免算法和慢启动算法需要对每个连接维持两个变量，一个拥塞窗口 cwnd 和一个慢启动门限 ssthresh。算法的工作过程如下：

1. 对于一个给定的连接，初始化 cwnd 为 1 个报文段，ssthresh 为 65535 个字节。TCP 滑动窗口大小不能超过 cwnd 和通告窗口的大小。开始执行慢启动算法，直到拥塞发生。

2. 当拥塞发生时（超时或收到重复确认），ssthresh 被设置为当前窗口大小的一半（cwnd 和接收方通告窗口大小的最小值，但最少为 2 个报文段）。此外，如果是超时引起了拥塞，则 cwnd 被设置为 1 个报文段（执行慢启动算法）。

3. 当新的数据被对方确认时，就增加 cwnd，但增加的方法依赖于我们是否正在进行慢启动或拥塞避免。如果 cwnd 小于或等于 ssthresh，则正在进行慢启动，否则正在进行拥塞避免。慢启动一直持续到我们回到当拥塞发生时所处位置的半时候才停止，然后转为执行拥塞避免。

### 什么是超时重传？

连续重传之间的时间差分别是 1.5、3、6、12、24、48 和 6 个 64 秒。第七个 64 秒后 TCP 发送方将放弃并发送 RST 报文段。首次重传与 RST 报文段的时间差约为 9 分钟。

### 什么是快速重传和快速恢复？

快重传算法要求在收到一个失序的报文段时， TCP 立即需要产生一个 ACK (一个重复的 ACK)，这个重复的 ACK 不应该被延迟。该重复的 ACK 的目的在于让对方知道收到一个失序的报文段，并告诉对方自己希望收到的序号。

如果一连串收到 3 个或 3 个以上的重复 ACK，就非常可能是一个报文段丢失了。于是就重传丢失的数据报文段，而无需等待超时定时器溢出，这就是快速重传算法。接下来执行的不是慢启动算法而是拥塞避免算法，这就是快速恢复算法。

在这种情况下没有执行慢启动的原因是由于收到重复的 ACK 不仅仅告诉我们一个分组丢失了。由于接收方只有在收到另一个报文段时才会产生重复的 ACK，而该报文段已经离开了网络并进入了接收方的缓存。也就是说，在收发两端之间仍然有流动的数据，而我们不想执行慢启动来突然减少数据流。

该算法的工作过程如下：

1. 当收到第 3 个重复的 ACK 时，将 ssthresh 设置为当前拥塞窗口 cwnd 的一半。重传丢失的报文段。设置 cwnd 为 ssthresh 加上 3 倍的报文段大小。

2. 每次收到另一个重复的 ACK 时，cwnd 增加 1 个报文段大小并发送 1 个分组（如果新的 cwnd 允许发送）。

3. 当下一个确认新数据的 ACK 到达时，设置 cwnd 为 ssthresh（在第1步中设置的值）。这个 ACK 应该是在进行重传后的一个往返时间内对步骤 1 中重传的确认。另外，这个 ACK 也应该是对丢失的分组和收到的第 1 个重复的 ACK 之间的所有中间报文段的确认。这一步采用的是拥塞避免，因为当分组丢失时我们将当前的速率减半。

### 什么是 keepalive？keepalive 有什么缺点？

如果 TCP 连接的双方都没有向对方发送数据，那么这个 TCP 连接将一直保持建立。此时如果其中一方主机崩溃，正常运行的一方就无法得知对方主机已崩溃，从而导致浪费资源。

RFC 提到一个实现可提供保活的功能，但是除非应用程序指明要这样，否则就不能使用该功能。而且，保活间隔必须是可配置的，但是其默认值必须不小于两个小时。

如果一个给定的连接在两个小时之内没有任何动作，则服务器就向客户发送一个探查报文段，服务器将会得到以下响应：

1. 客户机正常运行，并且服务器可达。服务器将重置保活定时器。

2. 客户机已经崩溃关机或者正在重启。服务器将会发送 10 个探查报文段，每个间隔 75 秒，之后就会认为客户机已经关闭并终止连接。

3. 客户机崩溃并已经重启。服务器将收到 RST 报文段，使得服务器终止这个连接。

4. 客户机正常，但服务器不可达（例如中间路由器崩溃）。这与第 2 条相同，因为 TCP 不能区分这两种情况。

保活定时器的缺点：

1. 在出现短暂差错的情况下，这可能会使一个非常好的连接释放掉。

2. 它们耗费不必要的带宽。

3. 在按分组计费的情况下会在互联网上花掉更多的钱。

4. keepalive 只能检测连接是否存活，不能检测连接是否可用。例如，某一方发生了死锁，无法在连接上进行任何读写操作，但是操作系统仍然可以响应网络层 keepalive 包。

5. TCP keepalive 机制依赖于操作系统的实现，灵活性不够，默认关闭，且默认的 keepalive 心跳时间是两个小时, 时间较长。

6. 代理服务器 (proxy server)、或者负载均衡器，会让 TCP keep-alive 失效

## UDP

### 什么是 UDP？什么时候用？

UDP (User Datagram Protocol) 是一个不提供可靠性，无连接的面向数据包的传输层协议。

UDP 由于其特性，适用于无须应答、一次只传输较小数据的情况，如语音视频电话会议等 C/S 系统等。

### 如何实现可靠的 UDP？

在选择传输层协议一般需要平衡传输成本、可靠性和时延的三角制约关系，TCP 是通过增大时延和传输成本来保证可靠的协议，UDP 是通过牺牲可靠来保证传输成本和时延的协议，所以有时我们需要找到它们之间的一个平衡点来定制自己的需求。

实现可靠 UDP 可以参照 TCP 的可靠实现，根据需求来选择实现部分机制来定制自己的协议。一般可靠 UDP 根据需求可分为：尽力可靠、无序可靠和有序可靠。

尽力可靠：通信的接收方要求发送方的数据尽量完整到达，但业务本身的数据是可以允许缺失的，例如：语音视频通话等业务。尽力可靠一般需要实现流量控制和拥塞避免机制。

无序可靠：通信的接收方要求发送方的数据必须完整到达，但可以不管到达的先后顺序，例如：文件传输、图形实时绘制数据、日志型数据等业务。无序可靠一般需要实现确认、重传、校验、丢弃重复、流量控制和拥塞避免等机制。

有序可靠：通信接收方要求发送方的数据必须按顺序完整到达，例如：弱网环境传输问题、带宽竞争问题、资源优化问题 (QUIC)。一般有序可靠在无序可靠的基础上实现排序功能即可。

目前有 RUDP、RTP 和 UDT 等开源库实现了可靠 UDP。

## DNS

### 什么是 DNS 协议？

DNS 协议是基于 UDP 的应用层协议，它的功能是根据用户输入的域名，解析出该域名对应的 IP 地址，从而给客户端进行访问。

### DNS 是怎么解析的？

1、客户机发出查询请求，在本地计算机缓存查找，若没有找到，就会将请求发送给dns服务器

2、本地dns服务器会在自己的区域里面查找，找到即根据此记录进行解析，若没有找到，就会在本地的缓存里面查找

3、本地服务器没有找到客户机查询的信息，就会将此请求发送到根域名dns服务器

4、根域名服务器解析客户机请求的根域部分，它把包含的下一级的dns服务器的地址返回到客户机的dns服务器地址

5、客户机的dns服务器根据返回的信息接着访问下一级的dns服务器

6、这样递归的方法一级一级接近查询的目标，最后在有目标域名的服务器上面得到相应的IP信息

7、客户机的本地的dns服务器会将查询结果返回给我们的客户机

8、客户机根据得到的ip信息访问目标主机，完成解析过程

## HTTP

### 什么是 HTTP 协议？

HTTP 是应用层的超文本传输协议（Hyper Text Transfer Protocol，HTTP），是一个简单的请求-响应协议，它运行在TCP之上。

### 什么是 HTTPS？

HTTP 协议的信息传输完全以明文方式，不做任何加密，不安全。HTTPS 协议在 HTTP 协议的基础上增加了 SSl/TLS 安全层。通常 HTTP 直接和 TCP 通信，而 HTTPS 先和 SSL 通信，再由 SSL 和 TCP 通信。在采用 SSL 后，HTTPS 拥有了加密、证书和完整性保护功能。

HTTP 和 HTTPS 的区别：

1. 安全性不同，https:// 前缀表明是用 SSL (安全套接字)或 TSL 加密的。

2. HTTPS 协议需要到 CA 申请证书，一般免费证书很少，需要交费，WEB 服务器启用 SSL 需要获得一个服务器证书并将该证书与要使用 SSL 的服务器绑定。

3. HTTP 和 HTTPS 使用的是完全不同的连接方式，同时使用的端口也不同，HTTP 使用的是 80 端口，HTTPS 使用的是 443 端口。

4. HTTP 的连接简单，是无状态的；HTTPS 协议是由 SSL + HTTP 协议构建的可进行加密传输、身份认证的网络协议，比 HTTP 协议安全。

5. 百度和谷歌两大搜索引擎都已经明确表示，HTTPS 网站将会作为搜索排名的一个重要权重指标。也就是说 HTTPS 网站比起 HTTP 网站在搜索排名中更有优势。

### 加密算法了解哪些？

加密算法一般分为对称加密和非对称加密。

对称加密就是加密和解密使用同一个秘钥。

非对称加密就是加密和解密所使用的不是同一个秘钥，通常有公钥和私钥两个秘钥，一般使用公钥加密，使用私钥解密。公钥是可以公开的，解决了网络中传输秘钥被窃听的风险。

### HTTPS 使用的哪种加密算法？

使用公钥加密通信生成对称加密秘钥，然后采用对称加密进行加密通信。

### 什么是 SSL 协议？

SSL 全称为 Secure Sockets Layer，即安全套接层，其继任为 TLS 传输层安全协议，均用于在传输层为数据通信提供安全支持。

SSL 协议的基本思路是采用公钥加密法，客户端先向服务器索要公钥，然后用公钥加密信息，服务器收到密文后，用自己的私钥解密。

SSL 依靠证书来验证公钥的真实有效，并为浏览器和服务器之间的通信加密。

### HTTPS 中公钥 (数字签名) 如何防止被别人篡改？如果有中间人攻击呢？

HTTPS 使用由数字证书认证机构 (CA) 颁发的公开秘钥证书，CA 是客户端和服务器双方都可信赖的第三方机构。

服务器的运营人员向 CA 提出公开秘钥的申请，CA 在判明提出申请者的身份之后，会对已申请的公开秘钥做数字签名，然后分配这个已签名的公开秘钥，并将该公开秘钥放入公钥证书后绑定在一起。

服务器会将这份公钥证书发送给客户端，以进行公开密钥加密方式通信。

接到证书的客户端可使用 CA 的公开秘钥，对证书上的数字签名进行验证，验证通过后，客户端便认为服务器的公开密钥是真实有效的。

此处 CA 的公开秘钥必须安全地转交给客户端。因此，多数浏览器开发商发布版本时，会事先在内部植入常用认证机关的公开秘钥。这样就能完全保证服务器的公开秘钥的真实有效。

### CA 证书中包含哪些内容？

证书序列号、证书过期时间、站点的组织名、站点的 DNS 主机名、站点的公开秘钥、证书颁发者的名称、证书颁发者的签名。

### 客户端收到 CA 证书如何校验其合法性，并验证其是否被篡改？

1. 日期检测，检查证书的起始日期和结束日期，以确保证书仍然有效；

2. 证书颁发者可信度检测，证书有不同的等级，每种证书要求不同等级的背景验证。

3. 签名检测，一旦判定签名授权是可信的，浏览器就要对签名使用签名颁发者的公开秘钥，并将其与校验码进行比较，以查看证书的完整性；

4. 站点身份检测，为防止服务器复制其他人的证书，或拦截其他人的流量，一般需要验证证书中的域名和对话的服务器的域名是否匹配。

### HTTPS 的握手流程？

HTTPS 客户端首先打开一条到 Web 服务器端口 443 的连接。当建立了 TCP 连接后，客户端和服务器就会初始化 SSL 层，对加密参数进行沟通，并交换秘钥。具体分为以下四步：

第一步：客户端向服务器发出加密通信的请求，这一步叫做 ClientHello 请求。在这一步，客户端主要向服务器提供的信息有：1、支持的协议版本，比如 TLS 1.0 版；2、一个客户端生成的随机数，稍后用于生成对话密钥；3、支持的加密方法，比如 RSA 公钥加密；4、支持的压缩方法。另外如果是虚拟主机的用户，客户端也可以向服务器提供它所请求的域名。

第二步：服务器收到客户端请求后，向客户端发出回应，这一步叫做 SeverHello。服务器的回应包含的信息有：1、确认使用的加密通信协议版本，比如 TLS 1.0 版本，如果浏览器与服务器支持的版本不一致，服务器关闭加密通信；2、一个服务器生成的随机数，稍后用于生成对话密钥；3、确认使用的加密方法，比如 RSA 公钥加密；4、服务器证书。除了上面这些信息，如果服务器需要确认客户端的身份，就会再包含一项请求，要求客户端提供客户端证书。比如，金融机构往往只允许认证客户连入自己的网络，就会向正式客户提供 USB 密钥，里面就包含了一张客户端证书。

第三步：客户端收到服务器回应以后，首先验证服务器证书。如果证书不是可信机构颁布、或者证书中的域名与实际域名不一致、或者证书已经过期，就会向访问者显示一个警告，由其选择是否还要继续通信。如果证书没有问题，客户端就会从证书中取出服务器的公钥。然后，向服务器发送三项信息：1、一个随机数。该随机数用服务器公钥加密，防止被窃听；2、编码改变通知，表示随后的信息都将用双方商定的加密方法和密钥发送；3、客户端握手结束通知，表示客户端的握手阶段已经结束。这一项同时也是前面发送的所有内容的 hash 值，用来供服务器校验。另外客户端通过之前的三个随机数生成会话秘钥。

第四步：服务器通过三个随机数生成会话秘钥，然后向客户端发送最后的信息：1、编码改变通知，表示随后的信息都将用双方商定的加密方法和密钥发送；2、服务器握手结束通知，表示服务器的握手阶段已经结束。这一项同时也是前面发送的所有内容的 hash 值，用来供客户端校验。

至此，整个握手阶段全部结束。此后，客户端和服务器之间使用生成的会话秘钥进行对称加密通信，除了加密之外，就完全是使用普通的 HTTP 协议。

为什么要使用三个随机数来生成会话秘钥？

答：一方面 SSL 不信任每个主机都能生成完全随机的随机数，如果随机数不随机，那么就有可能被猜出来，因此必须引入多个主机的随机因素，使用三个随机数一同生成秘钥就不容易被猜出来了。

### CA 证书给了什么东西到服务器端？

私钥

### CA 机构是如何用自己的私钥做数字签名？

采用 RSA 公钥加密算法，加密秘钥和解密秘钥是不同的秘钥，其公钥作为数字签名对外公布，私钥自我保留。使用公钥加密的内容只能用私钥解密。

一般先将数据进行哈希，然后使用自己私钥加密，作为数字签名。

### session 和 cookie 是什么？

HTTP 协议本身是无状态的，为了使其能处理更加复杂的逻辑，HTTP/1.1 引入 Cookie 来保存状态信息。

cookie 是由服务端产生的，再发送给客户端保存，当客户端再次访问的时候，服务器可根据 cookie 辨识客户端是哪个，以此可以做个性化推送，免账号密码登录等。

session 用于标记特定客户端信息，保存在服务器端。一般客户端带 cookie 对服务器进行访问，可通过 cookie 中的 session id 从整个 session 中查询到服务器记录的关于客户端的信息。

cookie 分为两类：会话 cookie 和 持久 cookie。会话 cookie 是一种临时 cookie，它记录了用户访问站点时的设置和偏好。用户退出浏览器时，会话 cookie 就被删除了。持久 cookie 的生存时间更长一些，它们存储在硬盘上，浏览器退出或计算机重启时它们仍然存在。会话 cookie 和持久 cookie 的唯一区别就是它们的过期时间。

### HTTP 会话相关信息保存在哪里？

浏览器将 http 会话相关信息保存在 cookie 中。

### HTTP 如何识别客户端，例如登录时缓存用户名和密码？

一般使用 cookie 来管理 session 识别客户端。实现原理是：

第一步：客户端通常使用 post 方法发送登录信息，如：用户 ID、密码等；

第二步：服务器通过登录信息进行身份验证，然后生成一个用来识别用户的 session id，并将 session id 与认证状态绑定后记录在服务端，然后通过首部 Set-Cookie 字段写入 session id 发送到客户端。

第三步：客户端将收到的 session id 作为 cookie 到本地内存，如果是持久 cookie，还需要将其保存到磁盘中，以后向该站点发送 HTTP 请求，浏览器会自动发送 cookie，session id 也随之发送到服务器，服务器通过接收到的 session id，来识别用户和其认证状态。

### cookie 在 HTTP 报文中如何使用？

cookie 是浏览器在客户端保存的 session id，浏览器在发送 http 请求时，会查看本地是否存在该站点的 cookie，如果存在，浏览器会自动将 cookie 中保存的 session id 添加到 http 首部的 Set-Cookie 或 Set-Cookie2 字段中，然后将 http 请求发送到服务器，服务器通过接收的 session id，来识别用户和其认证状态。

Set-Cookie 和 Set-Cookie2 字段是一个由“名字=值”这样的信息构成的列表。

### HTTP 中 chunked 编码了解吗？

一般 http 服务器使用 chunked 编码来实时生成消息长度，编码使用若干个 chunk 组成，有一个标明长度为 0 的 chunk 结束，每个 chunk 由两部组成，第一部分是该 chunk 的长度和长度单位，第二部分是指定长度的内容，每个部分用 CRLF 隔开。在最后一个长度为 0 的 chunk 中的内容称为 footer，是一些没有写的头部内容。

### 了解哪些 http 状态码？分别对应什么信息？

1XX：接收的信息正在处理

2XX：请求正常处理完毕

3XX：重定向

4XX：客户端错误

5XX：服务端错误

常见错误码： 301：永久重定向 302：临时重定向 304：资源没修改，用之前缓存就行 400：客户端请求的报文有错误 403：表示服务器禁止访问资源 404：表示请求的资源在服务器上不存在或未找到

### http 1.0、http 1.1 和 http 2.0 的改进有哪些？

http 1.0 规定了请求头和请求尾，响应头和响应尾 get 和 post，传输层使用的是 TCP 短连接。

http 1.1 默认开启长连接，在一个 TCP 连接上可以传送多个 HTTP 请求和响应。使用 TCP 长连接的方式改善了 HTTP/1.0 短连接造成的性能开销。另外支持管道（pipeline）网络传输，只要第一个请求发出去了，不必等其回来，就可以发第二个请求出去，可以减少整体的响应时间。服务端无法主动 push。

http 2.0 引入多路复用，引入多路复用前，文件是串行传输的，请求 a 文件，b 文件只能等待，并且连接数过多；引入多路复用后，a 文件 b 文件可以同时传输；引入了二进制数据帧，其中帧对数据进行顺序标识，有了序列 id，服务器就可以进行并行传输数据。

### get 和 post 的区别？

Get：指定资源请求数据，刷新无害，Get 请求的数据会附加到 url 中，因此传输数据的大小受到浏览器地址栏的限制。

Post：向指定资源提交要被处理的数据，刷新会使数据会被重复提交。post 在发送数据前会先将请求头发送给服务器进行确认，然后才真正发送数据。

### http 的短连接和长连接？

HTTP中的长连接短连接指HTTP底层TCP的连接。

短连接：客户端与服务器进行一次 HTTP 连接操作，就进行一次 TCP 连接，HTTP 连接结束则 TCP 关闭连接。

长连接：如果 HTTP 头部带有参数 keep-alive，即开启长连接网页完成打开后，底层用于传输数据的 TCP 连接不会直接关闭，会根据服务器设置的保活时间保持连接，保活时间过后连接关闭。

### http 转发和重定向的区别？

转发是服务器行为，服务器直接向目标地址访问 URL，将相应内容读取之后发给浏览器，用户浏览器地址栏 URL 不变，转发页面和转发到的页面可以共享 request 里面的数据。

重定向是利用服务器返回的状态码来实现的，如果服务器返回 301 或者 302，浏览器收到新的消息后自动跳转到新的网址重新请求资源。用户的地址栏 url 会发生改变，而且不能共享数据。

### 浏览器中输入一个网址后，具体发生了什么？

1. 进行DNS解析操作，根据DNS解析的结果查到服务器IP地址

2. 通过ip寻址和arp，找到服务器，然后三次握手建立TCP连接

3. 浏览器生成HTTP报文，发送HTTP请求，等待服务器响应

4. 服务器处理请求，并返回给浏览器

5. 根据HTTP是否开启长连接，进行TCP的挥手过程

6. 浏览器根据收到的静态资源进行页面渲染

## Linux 网络相关 API

### socket 函数？

socket 函数创建并返回一个文件描述符，可以指定 socket 的协议族、类型和协议。

bind() 函数把地址族的地址赋给 socket。

listen() 监听一个 socket，对应 TCP 服务端的 CLOSED 状态到 LISTEN 状态。

connect() 发出连接请求，对应 TCP 客户端的三次握手，阻塞 connect 在 TCP 三次握手完成后返回。服务端内核在三次握手后将已连接 socket 放入到已连接队列。

accept() 在已连接队列中取出一个 socket。

close() 关闭一个连接，对应 TCP 的四次挥手。

### accept 函数返回的时候发生在三次握手的哪个阶段？

accept 函数返回的是已经建立连接的 socket，client 在调用 connect 函数后，由内核进行 TCP 的三次握手，服务端在三次握手完成后将已连接 socket 放入的已连接队列，accept 只是中已连接队列取出最早的那一个 socket。

### send/recv 的返回值情形？

成功返回发送或结束的字节数，否则返回 -1，并设置 error 码。

### 你都知道哪些 TCP 选项？

SO_RCVBUF：接收缓冲区大小

SO_SNDBUF：发送缓冲区大小

SO_RCVLOWAT：接收缓冲区低水位标记

SO_SNDLOWAT：发送缓冲区低水位标记

SO_REUSEADDR：允许重用本地地址

SO_REUSEPORT：允许重用本地端口

SO_KEEPALIVE：周期性测试连接是否仍存活

SO_LINGER：若有数据待发送则延迟关闭

TCP_MAXSEG：TCP 最大分节大小

TCP_NODELAY：禁止 Nagle 算法

### 阻塞 socket 和非阻塞 socket 的区别？

阻塞式 socket 在进行系统调用时如果没有数据准备好，将一直等待内核将数据准备好，并复制到用户缓冲区后返回；非阻塞 socket 则不等待，直接返回。linux 下使用 fcntl 函数将 socket 设置为阻塞或非阻塞。

### 什么是同步 I/O 、异步 I/O？可以同步非阻塞吗？

同步 I/O 一般是指由用户进程主动调用 I/O 函数读写数据，处理数据；异步 I/O 是由内核将数据写入到用户缓冲区后进行事件或信号通知给用户进程，用户进程使用回调函数或信号处理函数来处理数据。

阻塞、非阻塞、I/O 复用、和信号驱动式 I/O 都是由用户进程调用 I/O 函数来读写数据，所以属于同步 I/O。

调用 aio_read 函数，给内核传递描述符、缓冲区指针、缓冲区大小和文件偏移，并且告诉内核当整个操作完成时如何通知我们。该函数调用后立即返回，不被阻塞，属于异步 I/O。

### 什么是 I/O 复用？

I/O 复用是指可以在单线程中处理多个描述符。它的原理是：用户进程将自己关心的描述符和对应的 I/O 事件告诉内核，如果内核发现用户进程指定的一个或多个 I/O 事件已就绪，它就会通知用户进程。linux 操作系统的 I/O 复用是由 select、poll 和 epoll 系统调用支持的。

I/O 的就绪事件分为可读、可写、异常。

可读事件：一个描述符对应的缓冲区中有数据可读。

可写事件：一个描述符对应的缓冲区中有剩余空间可以写入数据。

异常事件：一个描述符发生了特定的异常信息。

### select 的工作原理和优缺点？

select 的工作原理：

1. 首先定义指定监控事件的描述符集合 fd_set，调用 FD_ZERO 初始化集合后，调用 FD_SET 将需要监控的描述符添加到对应的可读、可写或异常事件的描述符集合中。

2. 调用 select 系统调用，内核会将可读、可写和异常描述符集合拷贝到内核缓冲区，然后对集合中所有的描述符进行轮询判断，当有描述符对应事件就绪或者等待超时后就会调用返回，返回后的集合中只保存了已就绪的描述符，集合中的其它描述符位图会被置 0，所以我们再次调用 select 时需要重新将描述符添加到对应的描述符集合中。

3. select 返回后，用户进程需要通过遍历描述符，判断哪些描述符还在集合中，就可以知道哪些描述符已经就绪了，然后处理对应的 IO 事件。

select 优点：

1. select 遵循 posix 标准，是跨平台的，可移植性好。

2. select 的等待超时时间的精度是微秒级的，而 poll 是毫秒级的。

select 缺点：

1. select 采用 fd_set 保存文件描述符，fd_set 是一个固定长度的位图，本质上是 long 数组，所以 select 监控的描述符数量有限制，该数量由宏 FD_SETSIZE 决定，默认 32 位系统为 1024，64 位系统为 2048。如果要改变 fd_set 的长度，则需要修改 FD_SETSIZZE 宏的大小并重新编译内核。

2. 每次调用 select 都会将描述符集合拷贝到内核中，然后轮询判断集合中的描述符是否就绪，拷贝和轮询的效率都比较低。

3. select 返回后的集合中只保存了已就绪的描述符，移除了未就绪的描述符，所以再次调用 select 时需要重新将描述符添加到对应的描述符集合中，然后重新拷贝的内核。

4. select 返回的集合是一个位图，而不是描述符数组，所以需要用户进程遍历判断哪个描述符在集合中，然后才能确认已就绪的描述符。

select 的相关接口有：
```c
// 清空集合
void FD_ZERO(fd_set *set);
// 向集合中添加描述符 fd
void FD_SET(int fd, fd_set *set);
// 从集合中删除描述符 fd
void FD_CLR(int fd, fd_set *set);
// 判断描述符是否在集合中
int  FD_ISSET(int fd, fd_set *set);

/**
 * DESCRIPTION:
 *  发起调用将集合拷贝到内核中并进行监控
 *
 * ARGUMENTS:
 *  set: 描述符位图
 *  nfds: 集合中最大描述符数值 + 1
 *  readfds: 可读事件集合
 *  writefds: 可写事件集合
 *  exceptfds: 异常事件集合
 *  timeout: 超时等待时间
 *    struct timeval {
 *        long tv_sec;  // 毫秒
 *        long tv_usec; // 微秒
 *    };
 * RETURN VALUE:
 */
int select(int nfds, fd_set *readfds, fd_set *writefds,
                  fd_set *exceptfds, struct timeval *timeout);
```

### poll 的工作原理和优缺点？

poll 的工作原理：

1. 首先定义 pollfd 结构体数组，将需要监控的描述符以及对应的事件信息添加进去。

2. 调用 poll 系统调用发起监控，内核会将数组中的数据拷贝到内核缓冲区并轮询判断，当有描述符就绪或者等待超时后调用返回，返回时将已就绪的事件添加进 pollfd 结构体中的 revents 中 (如果没有就绪的事件，则为 0)。

3. poll 系统调用返回后，用户进程遍历 pollfd 数组中每一个元素的 revents，根据对应的就绪事件进行处理。

poll 的优点：

1. poll 使用 pollfd 数组保存描述符和事件，需要多少描述符就定义多大的数组，因此监控的描述符数量没有限制。

2. poll 将已就绪事件放到数组元素的 revents 属性中返回，用户进程再次调用时不需要重新将描述符添加到数组。

poll 的缺点：

1. 每次调用 poll 都会将 pollfd 结构体数组拷贝到内核中，轮询判断描述符是否就绪，效率会随着描述符的增加而下降。

2. poll 系统调用返回后需要用户进程遍历数组判断每个元素的 revents 才能知道是哪个描述符就绪了哪个事件。

3. poll 无法跨平台移植。

4. poll 超时等待时间的精度是毫秒级的，select 是微秒级的。

```c
/**
 *  操作相对简单，如果某个描述符不需要继续监控时，直接将对应结构体中的 fd 置为 -1 即可。
 *
 * fds: pollfd 数组首地址
 *  struct pollfd 
 *  {
 *      int fd;         // 需要监控的文件描述符
 *      short events;   // 需要监控的事件
 *      short revents;  // 实际就绪的事件
 *  };
 * nfds: 数组的大小
 * timeout: 超时等待时间，单位为毫秒
 */
int poll(struct pollfd *fds, nfds_t nfds, int timeout);
```

### epoll 的工作原理和优缺点？

epoll 的工作原理：

1. 调用 epoll_create 系统调用，内核会创建一个 eventpoll 结构体，并返回一个描述符作为操作句柄。

2. 组织关心事件的结构体 epoll_event，调用 epoll_ctl 将描述符和对应事件添加到内核的 eventpoll 结构体中。

3. 调用 epoll_wait 开始监控，epoll 的监控是一个异步阻塞操作，他只需要告诉操作系统哪些描述符需要监控，然后这个监控的过程就由系统来完成。内核为每一个事件设置了一个回调函数，一旦对应事件就绪，就会自动调用回调函数，将描述符所对应的 epoll_event 事件结构体添加到 rdllist 双向链表中。

4. 调用 epoll_wait 后发起监控后，每隔一段时间就会去查看双向链表 rdllist 是否为空，如果链表不为空或者等待超时就调用返回，如果不为空则代表有描述符就绪，将就绪的描述符的结构信息添加到 epoll_wait 传入的 events 数组中。

5. 用户进程只需要对 events 数组进行遍历，判断就绪的是什么事件然后对描述符进行相应处理即可。

epoll 的优点：

1. epoll 使用红黑树保存描述符，监控的描述符数量没有限制，并且可以在 O(logn) 的时间动态增删。

2. epoll 内核实现是采用回调方式来检测就绪事件，时间复杂度是 O(1)，而 select 和 poll 是 O(n)。

3. epoll_wait 返回后，events 数组只保存了所有已就绪的描述符，用户进程只需要遍历 events 数组，不需要遍历所有监控描述符。

4. 支持 LT (Level Triggered，水平触发) 和 ET (Edge Triggered，边缘触发) 两种模式。

```c
struct eventpoll{  
   ...  
   /* 红黑树的根节点，这颗树中存储着所有添加到 epoll 中的需要监控的事件 */  
   struct rb_root rbr;  
   /* 双链表中则存放着将要通过 epoll_wait 返回给用户的满足条件的事件 */  
   struct list_head rdlist;  
   ...  
};  
/**
 * 在内核中创建eventpoll结构体，返回操作句柄 (size为监控的最大数量，但是在 
 * linux2.6.8 后忽略上限，只需要给一个大于 0 的数字即可)
 */
int epoll_create(int size);
/**
 * 组织描述符事件结构体
 *
 * epfd:eventpoll结构体的操作句柄
 * op:操作的选项，EPOLL_CTL_ADD/EPOLL_CTL_MOD/EPOLL_CTL_DEL
 * fd:描述符
 * event:监控描述符对应的事件信息结构体
 * struct epoll_event 
 * {
 *        uint32_t     events;    // 要监控的事件，以及调用返回后实际就绪的事件 
 *        epoll_data_t data;      // 联合体，用来存放各种类型的描述符 
 * };
 * typedef union epoll_data {
 *        void    *ptr;
 *        int      fd;
 *        uint32_t u32;
 *        uint64_t u64;
 * } epoll_data_t;
*/
int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event);
/**
 * 开始监控，当有描述符就绪或者等待超时后调用返回
 *
 * maxevents:events数组的结点数量
 * timeout:超时等待时间
 *
 * 返回值为就绪的描述符个数
 */
int epoll_wait(int epfd, struct epoll_event *events,
                      int maxevents, int timeout);
```

### select、poll 和 epoll 的区别？分别什么时候用？实现原理是什么？

select、poll、epoll 都是 I/O 复用的系统调用。select 遵循 posix 标准，是跨平台的，可移植性好，poll 和 epoll 是 linux 系统下对 select 的增强版。

从空间上看，select 采用 fd_set 保存监听 fds，有数量限制，默认 1024，如果要修改 fd_set 大小，需要修改 FD_SETSIZE 宏，并重新编译内核，每次调用 select 都需要重新将描述符添加到对应的描述符集合中。poll 采用数组来保存监听 fds，无数量限制，poll 将就绪事件保存在 revents 中，所以再次调用时不需要重新组织 pollfd 数组。epoll 采用红黑树来保存 fds，内部使用链表来保存已就绪事件，所以无数量限制，无多余拷贝。另外 select 和 poll 每次调用时需要将描述符拷贝到内核，epoll 只在第一次调用前拷贝一次。

从时间上看，select 和 poll 都是内核和用户进程判断就绪事件都是采用轮询遍历，时间复杂度是 O(n)，而 epoll 的内核基于 I/O 通知回调机制，用户进程直接遍历数组得到，时间复杂度是 O(1)。

从功能上看，select 和 poll 只有水平触发模式，epoll 支持两种工作方式，水平触发 (LT) 和边缘触发 (ET)，ET 模式只支持非阻塞读写，并且 epoll 不支持磁盘文件的 I/O 复用。

LT 模式：若就绪的事件在一次处理中没有处理完缓冲区的数据，内核会重复通知用户进程。

ET 模式：对于一个就绪的事件内核只通知一次。若就绪的事件在一次处理中没有处理完缓冲区的数据，内核将不会再次通知用户进程。为了保证数据的完整性，ET 模式只支持非阻塞的读写。

综上所述：需要跨平台时，选择 select；当只需要处理少量描述符并且描述符都比较活跃时，windows 选择 select，linux 选择 poll。当 linux 平台下处理高并发 I/O 时，优先选择 epoll。

### epoll 是同步还是异步的？

epoll 的实现是异步的，但 epoll 的 I/O 是同步的。

epoll 在内核态的 I/O 处理实现原理是是采用事件通知机制，调用事件的回调函数将描述符和对应的就绪事件添加到就绪链表中，所以 epoll 的实现是异步的。

《Unix 网络编程》这本书里的第六章讲到 Posix 的定义是：同步 I/O 会导致请求进程阻塞，直到 I/O 操作完成；异步 I/O 不会导致请求进程阻塞。epoll 在用户态调用 epoll_wait 系统调用时会阻塞，它真正的 I/O 是在用户态调用 send/recv 等系统调用同步完成的，所以 epoll 的 I/O 是同步的。

### epoll 的触发模型？水平触发和边缘触发？select 和 poll 分别是什么触发模型？

select 和 poll 只有水平触发模式，epoll 支持两种工作方式，水平触发 (LT) 和边缘触发 (ET)。

LT 模式：若就绪的事件在一次处理中没有处理完缓冲区的数据，内核会重复通知用户进程。

ET 模式：对于一个就绪的事件内核只通知一次。若就绪的事件在一次处理中没有处理完缓冲区的数据，内核将不会再次通知用户进程。为了保证数据的完整性，ET 模式只支持非阻塞的读写。

### 如何实现非阻塞 connect？

Berkeley 和 Posix 的实现有关与 select 和非阻塞 connect 有以下两个规则：

1. 当连接成功建立时，描述符变为可写。

2. 当建立连接遇到错误时，描述符变为即可读又可写。

非阻塞 connect 过程如下：

1. 调用 socket 创建 socketfd；

2. 填充 IP 地址、Port 和 协议族；

3. 调用 fcntl 设置为非阻塞模式；

4. 调用 connect 进行非阻塞连接，如果返回 0 则连接建立成功，否则，期望的错误是 EINPROGRESS，表示连接建立已经启动但还未完成；

5. 调用 select 等待套接字变为可读或可写，如果描述符变为可读或可写，需要使用 SO_ERROR 选项调用 getsocketopt 取得套接字的待处理错误，返回 0 表示连接建立成功，否则连接建立失败，需要取出 error 值来处理错误。

## protobuf

### protobuf 是什么？

protobuf 是 google 开源的一种轻量高效的结构化数据存储格式，类似于 json。它通过将结构化的数据进行序列化和反序列化，从而实现结构化数据的存储或 RPC 数据交换的功能。

序列化：将数据结构或对象转换成二进制串的过程。

反序列化：将通过序列化生成的二进制串转换成数据结构或对象的过程。

### protobuf 的优缺点？

protobuf 的优点：

1. 体积小，传输速度快。这是因为 protobuf 采用二进制数据流序列化结构数据。

2. 序列化和反序列化速度快。protobuf 的编码方式简单，只需要简单的数学运算和移位等操作。

3. 使用简单，proto 编译器自动进行序列化和反序列化；

4. 维护成本低，跨平台跨语言仅需维护一套 proto 对象协议；

5. 可扩展性好，不必破坏旧数据格式就可以对数据结构进行更新；

6. 加密性好，抓包只能看到二进制字节流。

protobuf 的缺点：

1. 不适合用于对基于文本的标记文档建模，因为文本不适合描述数据结构；

2. 目前的通用性较差，只有 google 在用；

3. 可读性差，以二进制数据流的方式存储，需要通过 .proto 文件才能了解到数据结构；

### protobuf 的应用场景？

protobuf 更小、更快、使用简单、维护成本低、加密性好，所以更适用于数据量大或网络环境不稳定的数据存储、RPC 数据交换的业务，例如，QQ、微信即时通信的业务。

### protobuf 的实现原理？

protobuf 的数据存储方式是 `Tag - Length - Value`，即 `标识 - 长度 - 字段值` 的存储方式。以 T-L-V 表示单个数据，最终将所有数据拼接成一个字节流，从而实现数据存储的功能。

## FQS & Solution

### TCP 某一端大量出现 CLOSE_WAIT 状态是什么现象？怎么解决?

在关闭 TCP 连接的过程中，被动关闭方在第 2 次握手后会进入 CLOSE_WAIT 状态，一般情况下被动关闭方是服务端，如果服务端有大量的 CLOSE_WAIT 状态的连接没有及时关闭，而客户端又不断地发送新的连接请求，这样就会打开的文件描述符数会不断增加。在 linux 系统中，一个进程最大可以同时打开的文件描述符是有上限的，ulimit -n 命令可以查看。当达到这个上限时，服务端进程将无法新建 socket 来响应新的连接请求。

如果出现此现象，必然存在大量的短连接，可以使用长连接解决。

### TCP 某一端大量出现 TIME_WAIT 是什么现象？怎么解决？

在关闭 TCP 连接的过程中，主动关闭方在第四次握手后会进入 TIME_WAIT 状态，在 2 MSL 时间后，进入 CLOSED 状态。TIME_WAIT 状态下，TCP 连接占用的端口无法被使用，因此，大量 TIME_WAIT 状态的存在，会导致新建 TCP 连接出错。

所以，出现问题的一端必然是主动关闭方，并且出现了大量的短连接。

解决方案有：

1. 使用长连接；

2. 缩减 TIME_WAIT 的时间，或允许 TIME_WAIT 状态的端口重用。

### 如何解决 TCP 的粘包和分片问题？

粘包和分片问题是因为 TCP 是字节流服务，内核将收到的报文段保存在内核缓冲区中，接收方应用层不知道消息之间的界限，不知道一次性提取多少字节的数据所造成的。

可以为字节流加上自定义固定长度的包头，一般包头中有协议版本号，魔数和包长度信息，接收方先 peek 固定长度的包头，然后使用 readn 函数取出一个包大小的数据。

### TODO 如何检查死链？心跳机制如何实现？

### TODO 断线重连机制如何设计？

### TODO 收发数据包正确的方式，收发缓冲区如何设计？

### TODO: 聊天室用 TCP 还是 UDP？为什么？
（问到qq聊天为啥要udp而非tcp，多播这一点复盘才想起来，可惜了）

### TODO: 如果用udp能不能一次性传输大文件？

### TODO: 一个比较大的数据报TCP和UDP分别怎么处理？UDP怎么保证分的包能被正确接收？

### TODO: 网络延迟比较高，能不能提出一个合理的方案去确定缓冲区大小？

能不能建个数学模型，会考虑哪些数据？给缓冲区定义一个公式？（直接就用tcp窗口大小表示对网络延迟大小的估计）

### TODO: 你刚刚说accept会阻塞，有没有不阻塞的方法？

### TODO:路由表的建表过程？

### TODO:arp 协议？